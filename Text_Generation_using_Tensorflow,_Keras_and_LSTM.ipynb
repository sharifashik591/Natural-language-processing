{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation using Tensorflow, Keras and LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYQid+5L0y0T60xvBBpgrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharifashik591/Natural-language-processing/blob/main/Text_Generation_using_Tensorflow%2C_Keras_and_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trnQG0-BbQFM"
      },
      "source": [
        "Generating text using nlp and tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP56EtDES6ld"
      },
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de5k5piSbON6"
      },
      "source": [
        "data=requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA2x4rBlS7c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9653859f-b211-47cc-c9f2-32af574901cc"
      },
      "source": [
        "data.text[:1000]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This is the 100th Etext file presented by Project Gutenberg, and\\nis presented in cooperation with World Library, Inc., from their\\nLibrary of the Future and Shakespeare CDROMS.  Project Gutenberg\\noften releases Etexts that are NOT placed in the Public Domain!!\\n\\nShakespeare\\n\\n*This Etext has certain copyright implications you should read!*\\n\\n<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\\nWITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\\nDISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\\nPERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\\nCOMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\\nSERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\\n\\n*Project Gutenberg is proud to cooperate with The World Library*\\nin the presentation of The Complete Works of William Shakespeare\\nfor your reading for educatio'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffCAs7Dyg6zS"
      },
      "source": [
        "data=data.text.split('\\n') #Split new line"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tigw69LVhY8Z"
      },
      "source": [
        "# data[0:253]\n",
        "data=data[253:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9dgxm-4b59k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f21910e-b78f-4a88-d16b-7e4e8b1ca63a"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWsOci3lcNeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29cd13d7-f90f-437d-c06e-8e5c09c2eac9"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  From fairest creatures we desire increase,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hscktwmnh9BY"
      },
      "source": [
        "data=\" \".join(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7pi3_-IioCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c69fdd4c-c749-413b-dfe7-25c8df020770"
      },
      "source": [
        "data[:1000]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  From fairest creatures we desire increase,   That thereby beauty's rose might never die,   But as the riper should by time decease,   His tender heir might bear his memory:   But thou contracted to thine own bright eyes,   Feed'st thy light's flame with self-substantial fuel,   Making a famine where abundance lies,   Thy self thy foe, to thy sweet self too cruel:   Thou that art now the world's fresh ornament,   And only herald to the gaudy spring,   Within thine own bud buriest thy content,   And tender churl mak'st waste in niggarding:     Pity the world, or else this glutton be,     To eat the world's due, by the grave and thee.                        2   When forty winters shall besiege thy brow,   And dig deep trenches in thy beauty's field,   Thy youth's proud livery so gazed on now,   Will be a tattered weed of small worth held:     Then being asked, where all thy beauty lies,   Where all the treasure of thy lusty days;   To say within thine own deep sunken eyes,   Were an all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjeBdHN-iqBo"
      },
      "source": [
        "def clean(doc):\n",
        "  token=doc.split()\n",
        "  table=str.maketrans('','',string.punctuation)\n",
        "  token=[w.translate(table) for w in token]\n",
        "  token=[word for word in token if word.isalpha()]\n",
        "  token=[word.lower() for word in token]\n",
        "  return token"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2V4fBIFlLzx"
      },
      "source": [
        "tokens=clean(data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyLbDeKhleCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6324fe55-57b4-413d-dc9b-824a6be48687"
      },
      "source": [
        "tokens[0:20]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['from',\n",
              " 'fairest',\n",
              " 'creatures',\n",
              " 'we',\n",
              " 'desire',\n",
              " 'increase',\n",
              " 'that',\n",
              " 'thereby',\n",
              " 'beautys',\n",
              " 'rose',\n",
              " 'might',\n",
              " 'never',\n",
              " 'die',\n",
              " 'but',\n",
              " 'as',\n",
              " 'the',\n",
              " 'riper',\n",
              " 'should',\n",
              " 'by',\n",
              " 'time']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13GkgkU5lhOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95dc953-231f-418b-bc9c-57872817902b"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "898199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd5XYNAimX23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988f8c48-b4ce-43aa-a320-7e630999afe1"
      },
      "source": [
        "len(set(tokens)) #total uniqie word"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6uzV_18msfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e97089d-0679-44cc-9bbd-29c24fc01fd0"
      },
      "source": [
        "#make sequence . \n",
        "\n",
        "length= 50+1\n",
        "lines= []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq=tokens[i-length:i]\n",
        "  line=' '.join(seq)\n",
        "  lines.append(line)\n",
        "\n",
        "  if i>250000:\n",
        "    break\n",
        "\n",
        "print(len(lines))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "249951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "I7nizjFpkjNF",
        "outputId": "911da2fc-34b2-47d6-cc2d-a684677931d4"
      },
      "source": [
        "lines[10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'might never die but as the riper should by time decease his tender heir might bear his memory but thou contracted to thine own bright eyes feedst thy lights flame with selfsubstantial fuel making a famine where abundance lies thy self thy foe to thy sweet self too cruel thou that'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qKtd92Rlkp4b",
        "outputId": "9d936382-2ffc-4413-a749-0094b6626303"
      },
      "source": [
        "tokens[500]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'were'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbrdl5bClv5W"
      },
      "source": [
        "Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3uNE1ldlFSz"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxcNoaHvlx9D"
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequence=tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQeOTAVmnX7j"
      },
      "source": [
        "sequence=np.array(sequence)\n",
        "\n",
        "x=sequence[:, :-1]\n",
        "y=sequence[:,-1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3mFORevntrT",
        "outputId": "7bd19b14-3366-4224-8a29-6eb9517e57c8"
      },
      "source": [
        "x[0] #first line"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   48,  1595,  1516,    36,   487,  1683,    10,  2908,  1381,\n",
              "        1224,   182,   121,   272,    21,    24,     1,  5584,    90,\n",
              "          30,    92,  5583,    18,   843,  1183,   182,   207,    18,\n",
              "         868,    21,    26,  3775,     5,   223,   119,  1325,   168,\n",
              "       14869,    32,  2609,  2052,    16, 14868, 14867,   826,     6,\n",
              "        3774,   101,  2222,   432,    32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZWQ3KcAnzC_",
        "outputId": "0bc4bfb3-7b2c-4479-e0bc-6d822e56d135"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TC5E_Oyn8IT"
      },
      "source": [
        "\n",
        "vocab_size=len(tokenizer.word_index) +1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiJldEqmqurt"
      },
      "source": [
        "seq_length=x.shape[1]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvhQJyQnoXcr"
      },
      "source": [
        "y=to_categorical(y, num_classes=voc_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS7ptth0raes"
      },
      "source": [
        "LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy_bj3lSo3cj"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7txBpsyrdlj"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGF2KNoWrfl-"
      },
      "source": [
        "model.fit(x, y, batch_size = 256, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j347Vw1Arfjb"
      },
      "source": [
        "seed_text=lines[12343]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlw7oBqlrfhx"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmpzphh_rfed"
      },
      "source": [
        "print(generate_text_seq(model, tokenizer, seq_length, seed_text, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWfcx-aSsLmq"
      },
      "source": [
        "'preposterously be stained to leave for them when thou art covetous and we pour their natural fortune grace the other fool as a monkey i cannot weep and ends you clown nay ay my lord ham aside the queen quoth thou into sport angelo to th capitol brutus patience peace night i am returnd to th field o th gout and a man that murdred of the greatest rout of her particular occasions that outruns the world side corioli did my performance gone cut the offender and take thee to you that dare not go and show me to be'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhQTly2gs7Ep"
      },
      "source": [
        "Tutorial Link : https://www.youtube.com/watch?v=VAMKuRAh2nc&list=PL-KyHBP_QcTvYB_9_lkd_PJQS_f7_Gm_e&index=1&t=1529s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI6LL7TtrfbL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}